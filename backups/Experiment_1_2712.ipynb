{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27584213",
   "metadata": {},
   "source": [
    "# Experiment 1. Predicting risk of recurrence and risk of death"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c4a66c",
   "metadata": {},
   "source": [
    "## Reading the dataset and removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b7d64ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(922, 95) (922, 7) (922, 88)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recurrence event(s)</th>\n",
       "      <th>Days to local recurrence</th>\n",
       "      <th>Days to distant recurrence</th>\n",
       "      <th>Days to death</th>\n",
       "      <th>Days to last local recurrence free assessment</th>\n",
       "      <th>Days to last distant recurrence free assessment</th>\n",
       "      <th>Days known alive / to death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NP</td>\n",
       "      <td>NP</td>\n",
       "      <td>NP</td>\n",
       "      <td>2940</td>\n",
       "      <td>2940</td>\n",
       "      <td>2940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NP</td>\n",
       "      <td>NP</td>\n",
       "      <td>NP</td>\n",
       "      <td>1649</td>\n",
       "      <td>1649</td>\n",
       "      <td>1649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NP</td>\n",
       "      <td>NP</td>\n",
       "      <td>NP</td>\n",
       "      <td>1697</td>\n",
       "      <td>1697</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NP</td>\n",
       "      <td>NP</td>\n",
       "      <td>NP</td>\n",
       "      <td>1990</td>\n",
       "      <td>1990</td>\n",
       "      <td>1990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NP</td>\n",
       "      <td>NP</td>\n",
       "      <td>NP</td>\n",
       "      <td>1845</td>\n",
       "      <td>1845</td>\n",
       "      <td>1845.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recurrence event(s) Days to local recurrence Days to distant recurrence  \\\n",
       "0                  0.0                       NP                         NP   \n",
       "1                  0.0                       NP                         NP   \n",
       "2                  0.0                       NP                         NP   \n",
       "3                  0.0                       NP                         NP   \n",
       "4                  0.0                       NP                         NP   \n",
       "\n",
       "  Days to death Days to last local recurrence free assessment  \\\n",
       "0            NP                                          2940   \n",
       "1            NP                                          1649   \n",
       "2            NP                                          1697   \n",
       "3            NP                                          1990   \n",
       "4            NP                                          1845   \n",
       "\n",
       "  Days to last distant recurrence free assessment  Days known alive / to death  \n",
       "0                                            2940                       2940.0  \n",
       "1                                            1649                       1649.0  \n",
       "2                                            1697                          NaN  \n",
       "3                                            1990                       1990.0  \n",
       "4                                            1845                       1845.0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read dataset\n",
    "duke = pd.read_excel(\n",
    "    \"../data/DUKE_edit.xlsx\",\n",
    "    skiprows = [0,2],\n",
    "    usecols = \"A:CT\"\n",
    ")\n",
    "\n",
    "# Remove empty column and irrelevants id and position in a 3D image columns\n",
    "duke = duke.drop(columns=['Unnamed: 67', 'Patient ID', 'Image Position of Patient'])\n",
    "\n",
    "# Columns containing info from labels and correlated to them\n",
    "label_cols = list(range(58,65))\n",
    "\n",
    "# Columns containing info from images (MRI and US)\n",
    "image_cols = list(range(17)) + list(range(46,51)) + list(range(66,72))\n",
    "\n",
    "# Create DataFrames removing unnecessary columns\n",
    "labels = duke.iloc[:, label_cols]\n",
    "data = duke.drop(labels, axis=1)\n",
    "#data = data_image.drop(data_image.columns[image_cols], axis=1)\n",
    "\n",
    "# Print the shapes of each DataFrame\n",
    "print(duke.shape, labels.shape, data.shape)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6778384c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Days to MRI', 'Manufacturer', 'Manufacturer Model Name',\n",
      "       'Scan Options', 'Field Strength (Tesla)', 'Patient Position During MRI',\n",
      "       'Contrast Agent', 'Contrast Bolus Volume (mL)', 'TR (Repetition Time)',\n",
      "       'TE (Echo Time)', 'Acquisition Matrix', 'Slice Thickness ', 'Rows',\n",
      "       'Columns', 'Reconstruction Diameter ', 'Flip Angle \\n',\n",
      "       'FOV Computed (Field of View) in cm ', 'Date of Birth (Days)',\n",
      "       'Menopause (at diagnosis)', 'Race and Ethnicity',\n",
      "       'Metastatic at Presentation (Outside of Lymph Nodes)', 'ER', 'PR',\n",
      "       'HER2', 'Mol Subtype', 'Oncotype score', 'Staging(Tumor Size)# [T]',\n",
      "       'Staging(Nodes)#(Nx replaced by -1)[N]',\n",
      "       'Staging(Metastasis)#(Mx -replaced by -1)[M]', 'Tumor Grade (T)',\n",
      "       'Tumor Grade (N)', 'Tumor Grade (M)', 'Nottingham grade',\n",
      "       'Histologic type', 'Tumor Location', 'Position',\n",
      "       'Bilateral breast cancer?', 'If Bilateral, Different Rec Status',\n",
      "       'Bilateral side annotated', 'If bilateral, side of cancer (other side)',\n",
      "       'Oncotype score (other side)', 'Nottingham grade (other side)',\n",
      "       'ER (other side)', 'PR (other side)', 'HER2 (other side)',\n",
      "       'Mol Subtype (other side)', 'Multicentric/Multifocal',\n",
      "       'Contralateral Breast Involvement',\n",
      "       'Lymphadenopathy or Suspicious Nodes', 'Skin/Nipple Involvement',\n",
      "       'Pec/Chest Involvement', 'Surgery', 'Days to Surgery',\n",
      "       'Definitive Surgery Type', 'Neoadjuvant Radiation Therapy',\n",
      "       'Adjuvant Radiation Therapy', 'Clinical Response',\n",
      "       'Pathologic Response to Neoadjuvant Therapy', 'Days at mammo',\n",
      "       'Breast Density', 'Shape', 'Margin', 'Architectural distortion',\n",
      "       'Mass Density', 'Calcifications', 'Tumor Size (cm)', 'Shape.1',\n",
      "       'Margin.1', 'Tumor Size (cm).1', 'Echogenicity', 'Solid',\n",
      "       'Posterior acoustic shadowing', 'Neoadjuvant Chemotherapy',\n",
      "       'Adjuvant Chemotherapy', 'Neoadjuvant Endocrine Therapy Medications ',\n",
      "       'Adjuvant Endocrine Therapy Medications ', 'Known Ovarian Status ',\n",
      "       'Number of Ovaries In Situ \\n',\n",
      "       'Therapeutic or Prophylactic Oophorectomy as part of Endocrine Therapy ',\n",
      "       'Neoadjuvant Anti-Her2 Neu Therapy', 'Adjuvant Anti-Her2 Neu Therapy ',\n",
      "       'Received Neoadjuvant Therapy', 'Neoadjuvant therapy: stage (T)',\n",
      "       'Neoadjuvant therapy: stage (N)', 'Neoadjuvant therapy: stage (M)',\n",
      "       'Overall Near-complete Response:  Stricter Definition',\n",
      "       'Overall Near-complete Response:  Looser Definition',\n",
      "       'Near-complete Response (Graded Measure)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the columns' labels so that they can be easily used\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca06612",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d699bff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If Bilateral, Different Rec Status\n",
      "NP    623\n",
      "NC    271\n",
      "0      26\n",
      "1       2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "If Bilateral, Different Rec Status\n",
      "0.0    26\n",
      "1.0     2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Print types of values of a int column containing strings\n",
    "print(data['If Bilateral, Different Rec Status'].value_counts(), end='\\n\\n')\n",
    "\n",
    "# Replace all instances of 'NC' and 'NP' with NaN\n",
    "data.replace('NC', np.nan, inplace=True)\n",
    "data.replace('NP', np.nan, inplace=True)\n",
    "\n",
    "# Print again\n",
    "print(data['If Bilateral, Different Rec Status'].value_counts())\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Loop through columns that are of type 'object' (categorical columns)\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    data[column] = label_encoder.fit_transform(data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9742c346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local recurrence\n",
      "0    906\n",
      "1     16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distant recurrence\n",
      "0    846\n",
      "1     76\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Recurrence\n",
      "0    832\n",
      "1     90\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dead\n",
      "0    860\n",
      "1     62\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Recurrence and death will be the labels for our experiment\n",
    "labels.loc[:,'Local recurrence'] = np.where(labels['Days to local recurrence'] != 'NP', 1, 0)\n",
    "labels.loc[:,'Distant recurrence'] = np.where(labels['Days to distant recurrence'] != 'NP', 1, 0)\n",
    "labels.loc[:,'Recurrence'] = np.logical_or(labels['Local recurrence'], labels['Distant recurrence']).astype(int)\n",
    "labels.loc[:,'Dead'] = np.where(labels['Days to death'] != 'NP', 1, 0)\n",
    "\n",
    "# Number how many of each label we have\n",
    "print(labels['Local recurrence'].value_counts(), labels['Distant recurrence'].value_counts(),\n",
    "      labels['Recurrence'].value_counts(), labels['Dead'].value_counts(), sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed2e9c2",
   "metadata": {},
   "source": [
    "## Predicting risk of recurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "09d34175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      " Recurrence\n",
      "0    665\n",
      "1     72\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set class distribution:\n",
      " Recurrence\n",
      "0    167\n",
      "1     18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define target label\n",
    "y = labels['Recurrence']\n",
    "\n",
    "# Perform stratified 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Display the class distribution in the train and test sets\n",
    "print(\"Training set class distribution:\\n\", y_train.value_counts())\n",
    "print()\n",
    "print(\"Test set class distribution:\\n\", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "34186ffd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m----> 6\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m      9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1207\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1205\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1207\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1208\u001b[0m     X,\n\u001b[0;32m   1209\u001b[0m     y,\n\u001b[0;32m   1210\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1211\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_dtype,\n\u001b[0;32m   1212\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1213\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1214\u001b[0m )\n\u001b[0;32m   1215\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
